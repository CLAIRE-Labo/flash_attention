# flash_attention
A basic pure pytorch implementation of flash attention
